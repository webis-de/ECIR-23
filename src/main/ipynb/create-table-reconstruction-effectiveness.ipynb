{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e8090d-ac95-474b-b9d8-48e8d67dc376",
   "metadata": {},
   "source": [
    "# Create table `table-reconstruction-effectiveness`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08c226-a028-4b77-872c-e1d3b6807423",
   "metadata": {},
   "source": [
    "### Import utility and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e01a2d-f146-442d-a9ce-d254e1915827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3488/3488 [02:01<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 21.2 s, total: 3min 21s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "sys.path.append('../python/')\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from parametrized_bootstrapping_model import ParametrizedBootstrappingModel, ReturnAlways1Model, ReturnAlways0Model\n",
    "from result_analysis_utils import load_ground_truth_data, load_evaluations, run_cross_validation, load_cross_validation_results, load_raw_evaluations\n",
    "SEARCH_SPACE= [0, 1, 2] + list(range(5,96, 5)) + [98, 99, 100]\n",
    "from io import StringIO\n",
    "from trectools import TrecQrel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from reconstruction_evaluation import ReconstructionEvaluation, DataConstruction\n",
    "import json\n",
    "\n",
    "if 'df' not in locals() or 'unique_queries' not in locals():\n",
    "    eval_predictions = glob('../resources/eval/trec-system-runs/trec13/*.jsonl')\n",
    "    eval_predictions += list(load_cross_validation_results(open('cross-validation-results/bs-p-1000-ndcg@10-ndcg@10-results.jsonl'), depth=10, return_buffers=True))\n",
    "    eval_predictions += list(load_cross_validation_results(open('cross-validation-results/bs-pool-dependent-1000-ndcg@10-ndcg@10-results.jsonl'), depth=10, return_buffers=True))\n",
    "    eval_predictions += list(load_cross_validation_results(open('cross-validation-results/bs-run-and-pool-dependent-1000-ndcg@10-ndcg@10-results.jsonl'), depth=10, return_buffers=True))\n",
    "    eval_predictions += list(load_cross_validation_results(open('cross-validation-results/bs-run-dependent-1000-ndcg@10-ndcg@10-results.jsonl'), depth=10, return_buffers=True))\n",
    "    \n",
    "    df = load_evaluations(tqdm(eval_predictions))\n",
    "    \n",
    "    unique_queries = set(TrecQrel('../resources/unprocessed/topics-and-qrels/qrels.robust04.txt').qrels_data['query'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d37410-ce6a-47db-b878-135b2b076381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [00:01<00:00, 105.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def report_for_row(df_row, measure, depth):\n",
    "    tmp = {'run': df_row['run'].split('/')[-1].replace('input.', '').replace('.gz', '')}\n",
    "    measures = [\n",
    "        ('unjudged', (f'depth-{depth}-incomplete', f'unjudged@{depth}')),\n",
    "        (f'ground-truth-{measure}@{depth}', (f'depth-{depth}-complete', f'ndcg@{depth}')),\n",
    "        (f'min-residual-{measure}@{depth}', (f'depth-{depth}-incomplete', f'residual-{measure}@{depth}-min')),\n",
    "        (f'condensed-{measure}@{depth}', (f'depth-{depth}-incomplete', f'condensed-{measure}@{depth}')),\n",
    "        (f'max-residual-{measure}@{depth}', (f'depth-{depth}-incomplete', f'residual-{measure}@{depth}-max')),\n",
    "        (f'always-1', (f'depth-{depth}-incomplete', 'always-1')),\n",
    "        (f'always-0', (f'depth-{depth}-incomplete', 'always-0')),\n",
    "    ]\n",
    "    \n",
    "    for k,v in [('PBS', f'bs-p-1000-{measure}@{depth}-{measure}@{depth}'), ('PBS-P', f'bs-pool-dependent-1000-{measure}@{depth}-{measure}@{depth}'), ('PBS-RP', f'bs-run-and-pool-dependent-1000-{measure}@{depth}-{measure}@{depth}'), ('PBS-R', f'bs-run-dependent-1000-{measure}@{depth}-{measure}@{depth}')]:\n",
    "        for m in ['[0.6,1]', '', '[0.8,1]', '[1,2]', '[1,3]', '[0.1,5]', '[0.1,10]', '[0.1,100]', '[0,1]']:\n",
    "            measures += [(f'{k}-RMSE{m}-{measure}@{depth}', (f'depth-{depth}-incomplete', f'pbs-rmse{m}-{v}'))]\n",
    "    \n",
    "    for display_name, m in measures:\n",
    "        try:\n",
    "            tmp[display_name] = json.loads(df_row[m])\n",
    "        except:\n",
    "            raise ValueError(m)\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for topic in tmp[f'ground-truth-{measure}@{depth}']:\n",
    "        entry = {'run': tmp['run'], 'topic': topic}\n",
    "        for k, v in tmp.items():\n",
    "            if k in ['run']:\n",
    "                continue\n",
    "            \n",
    "            if topic in v:\n",
    "                entry[k] = v[topic]\n",
    "        ret += [entry]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def create_aggregated_df(measure, depth, loc):\n",
    "    ret = pd.DataFrame([dict(i) for i in report_for_row(df.iloc[loc], measure, depth)])\n",
    "    ret = ret.sort_values(f'ground-truth-{measure}@{depth}', ascending=False).reset_index()\n",
    "    del ret['index']\n",
    "    return ret\n",
    "\n",
    "\n",
    "def data_for_reconstruction_experiments():\n",
    "    ret = {}\n",
    "    for run in tqdm(range(110)):\n",
    "        try:\n",
    "            tmp = create_aggregated_df('ndcg', 10, run)\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            continue\n",
    "        tmp = tmp[tmp['unjudged'] > 0].dropna()\n",
    "        if len(tmp) < 50:\n",
    "            continue\n",
    "\n",
    "        measures_to_report = [('Condensed', 'condensed-ndcg@10'), ('Min-Residual', 'min-residual-ndcg@10'),\n",
    "                    ('Max-Residual', 'max-residual-ndcg@10'), ('Always 1', 'always-1'), ('Always 0', 'always-0'),\n",
    "                   ]\n",
    "\n",
    "        for i in ['[0.6,1]', '', '[0.8,1]', '[1,2]', '[1,3]']:\n",
    "            for p in ['', 'P-', 'RP-', 'R-']:\n",
    "                measures_to_report += [(f'PBS-{p}RMSE{i}', f'PBS-{p}RMSE{i}-ndcg@10')]\n",
    "\n",
    "                \n",
    "        for _, i in tmp.iterrows():\n",
    "            to_add = {\n",
    "                'topic': i['topic'],\n",
    "                'system': i['run'],\n",
    "                'ground_truth': i['ground-truth-ndcg@10']\n",
    "            }\n",
    "            \n",
    "            for k,v in measures_to_report:\n",
    "                to_add[k] = i[v]\n",
    "            \n",
    "            if i['topic'] not in ret:\n",
    "                ret[i['topic']] = []\n",
    "            \n",
    "            ret[i['topic']] += [to_add]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "d = data_for_reconstruction_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ccb50d7-ca49-4890-8050-31729099fea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PBS-P</td>\n",
       "      <td>0.936807</td>\n",
       "      <td>0.828982</td>\n",
       "      <td>0.869048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PBS-R</td>\n",
       "      <td>0.952959</td>\n",
       "      <td>0.835189</td>\n",
       "      <td>0.878572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PBS-RP</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.836975</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Residuals</td>\n",
       "      <td>0.935703</td>\n",
       "      <td>0.415869</td>\n",
       "      <td>0.540361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    approach  precision    recall        f1\n",
       "0      PBS-P   0.936807  0.828982  0.869048\n",
       "1      PBS-R   0.952959  0.835189  0.878572\n",
       "2     PBS-RP   0.951172  0.836975  0.879491\n",
       "3  Residuals   0.935703  0.415869  0.540361"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_approaches = {\n",
    "    'Residuals': DataConstruction('Min-Residual', 'Condensed', 'Max-Residual'),\n",
    "    'PBS-RP': DataConstruction('PBS-RP-RMSE[0.8,1]', 'PBS-RP-RMSE', 'PBS-RP-RMSE[1,3]'),\n",
    "    'PBS-R': DataConstruction('PBS-R-RMSE[0.8,1]', 'PBS-R-RMSE', 'PBS-R-RMSE[1,3]'),\n",
    "    'PBS-P': DataConstruction('PBS-P-RMSE[0.8,1]', 'PBS-P-RMSE', 'PBS-P-RMSE[1,3]')\n",
    "}\n",
    "\n",
    "df_reconstruction = []\n",
    "\n",
    "reconstruction_eval = ReconstructionEvaluation()\n",
    "\n",
    "for approach_name, approach in reconstruction_approaches.items():\n",
    "    for topic, topic_data in approach.construct_data_for_reconstruction_evaluation(d).items():\n",
    "        df_reconstruction += [{\n",
    "            'approach': approach_name,\n",
    "            'topic': topic,\n",
    "            'precision': reconstruction_eval.precision(topic_data),\n",
    "            'recall': reconstruction_eval.recall(topic_data),\n",
    "        }]\n",
    "\n",
    "df_reconstruction = pd.DataFrame(df_reconstruction)\n",
    "df_reconstruction['f1'] = df_reconstruction.apply(lambda i: 0 if (i['precision']+i['recall']) == 0 else 2*(i['precision']*i['recall'])/(i['precision']+i['recall']), axis=1)\n",
    "df_reconstruction = df_reconstruction[['approach', 'precision', 'recall', 'f1']].groupby('approach').mean().reset_index()\n",
    "df_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7614770d-24c3-4b28-975b-1687ea90b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[t]\n",
      "\\caption{Reconstruction effectiveness: Precision (how many of the system-pairs that I tell apart are correct?), Recall (how many of the apart system pairs do I find?), and F1 as the harmonic mean of precision and recall. All of this on the Topic Level. {\\color{red} ToDo: Look why precision of residuals is not 1, are these only the special cases that we discussed earlier?}}\n",
      "\\label{table-reconstruction-effectiveness}\n",
      "\\renewcommand{\\tabcolsep}{3.8pt} \n",
      "\\centering\n",
      "\\small\n",
      "\n",
      "\\begin{tabular}{@{}l@{\\hspace{2em}}c@{\\hspace{.5em}}c@{\\hspace{.5em}}c@{\\hspace{2em}}c@{\\hspace{.5em}}c@{\\hspace{.5em}}c@{\\hspace{2em}}c@{\\hspace{.5em}}c@{\\hspace{.5em}}c@{}}\n",
      "\\toprule\n",
      "& \\multicolumn{3}{c}{Reconstr. on Robust04} & \\multicolumn{3}{c}{Reconstr. on CW09} & \\multicolumn{3}{c}{Reconstr. on CW12} \\\\\n",
      "\\cmidrule(r{1em}){2-4} \\cmidrule(r{1em}){5-7} \\cmidrule{8-10}\n",
      "\n",
      " & Precision                & Recall         & F1   & Precision                & Recall         & F1 & Precision                & Recall         & F1             \\\\\n",
      "\\midrule\n",
      "Residuals & 0.936 & 0.416 & 0.54 &  --- & --- & --- & --- & --- & ---\\\\\n",
      "Min Res. +-x\\% & --- & --- & --- &  --- & --- & --- & --- & --- & ---\\\\\n",
      "Cond. Lists +-x\\% & --- & --- & --- & --- & --- & --- & --- & --- & ---\\\\\n",
      "\n",
      "\\midrule\n",
      "BS (R) &  0.953 & 0.835 & 0.879 &  --- & --- & --- & --- & --- & ---\\\\\n",
      "BS (P) &  0.937 & 0.829 & 0.869 &  --- & --- & --- & --- & --- & ---\\\\\n",
      "BS (R+P) &  0.951 & 0.837 & 0.879 &  --- & --- & --- & --- & --- & ---\\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular} \n",
      "\\end{table*} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def line(df, name):\n",
    "    df = df[df['approach'] == name]\n",
    "    assert len(df) == 1\n",
    "    df = df.iloc[0].to_dict()\n",
    "    \n",
    "    return f'{round(df[\"precision\"], 3)} & {round(df[\"recall\"], 3)} & {round(df[\"f1\"], 3)} &  --- & --- & --- & --- & --- & ---'\n",
    "\n",
    "def produce_table(df):\n",
    "    return '''\\\\begin{table*}[t]\n",
    "\\\\caption{Reconstruction effectiveness: Precision (how many of the system-pairs that I tell apart are correct?), Recall (how many of the apart system pairs do I find?), and F1 as the harmonic mean of precision and recall. All of this on the Topic Level. {\\\\color{red} ToDo: Look why precision of residuals is not 1, are these only the special cases that we discussed earlier?}}\n",
    "\\\\label{table-reconstruction-effectiveness}\n",
    "\\\\renewcommand{\\\\tabcolsep}{3.8pt} \n",
    "\\\\centering\n",
    "\\\\small\n",
    "\n",
    "\\\\begin{tabular}{@{}l@{\\\\hspace{2em}}c@{\\\\hspace{.5em}}c@{\\\\hspace{.5em}}c@{\\\\hspace{2em}}c@{\\\\hspace{.5em}}c@{\\\\hspace{.5em}}c@{\\\\hspace{2em}}c@{\\\\hspace{.5em}}c@{\\\\hspace{.5em}}c@{}}\n",
    "\\\\toprule\n",
    "& \\\\multicolumn{3}{c}{Reconstr. on Robust04} & \\\\multicolumn{3}{c}{Reconstr. on CW09} & \\\\multicolumn{3}{c}{Reconstr. on CW12} \\\\\\\\\n",
    "\\\\cmidrule(r{1em}){2-4} \\\\cmidrule(r{1em}){5-7} \\\\cmidrule{8-10}\n",
    "\n",
    " & Precision                & Recall         & F1   & Precision                & Recall         & F1 & Precision                & Recall         & F1             \\\\\\\\\n",
    "\\\\midrule\n",
    "Residuals & ''' + line(df, 'Residuals') + '''\\\\\\\\\n",
    "Min Res. +-x\\\\% & --- & --- & --- &  --- & --- & --- & --- & --- & ---\\\\\\\\\n",
    "Cond. Lists +-x\\\\% & --- & --- & --- & --- & --- & --- & --- & --- & ---\\\\\\\\\n",
    "\n",
    "\\\\midrule\n",
    "BS (R) &  ''' + line(df, 'PBS-R') + '''\\\\\\\\\n",
    "BS (P) &  ''' + line(df, 'PBS-P') + '''\\\\\\\\\n",
    "BS (R+P) &  ''' + line(df, 'PBS-RP') + '''\\\\\\\\\n",
    "\n",
    "\\\\bottomrule\n",
    "\\\\end{tabular} \n",
    "\\\\end{table*} \n",
    "'''\n",
    "\n",
    "print(produce_table(df_reconstruction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
