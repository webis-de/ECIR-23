{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cb5faf-267a-4879-b20f-ccd3d683156b",
   "metadata": {},
   "source": [
    "# Sample Eval Pilot Study\n",
    "\n",
    "This is a pilot study to evaluate if infNDCG in the original implementation (can be downloaded from: https://trec.nist.gov/data/medical/12/sample_eval.pl) should be included in our experiments or not.\n",
    "From reading the original paper, I think infNDCG would make not too much sense as it addresses a different problem: \"support fair comparison of retrieval results using relatively small amounts of judging effort\" [[1](https://dl.acm.org/doi/pdf/10.1145/2600428.2609524)]. I.e., it is a technique to construct a judgment-set that uses details on the document sampling that it applied (i.e., it partitions documents into strata during construction of the judgment set from which documents can be judged with different probabilities) to calculate the inferred NDCG. However, in our situation, the judgment pool was constructed with pooling. Hence, the requirements for infNDCG (i.e., the strata) are not applicable).\n",
    "\n",
    "\n",
    "This script contains an implementation of infNDCG. I copied this script to `sample_eval_depth_10.pl` where I adopted the maxResultSize to 10 so that we calculate infNDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fbed01-f717-4d05-b57c-9f4ad99a8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../ipynb/beir-evaluation-data/incomplete-beir-trec-covid.txt', 'r') as input_file, open('incomplete-beir-trec-covid-for-sample-eval.txt', 'w') as output_file:\n",
    "    for l in input_file:\n",
    "        l = l.split()\n",
    "        # We only have one strata\n",
    "        l = l[0] + ' ' + l[1] + ' ' + l[2] + ' 1 ' + l[3]\n",
    "        output_file.write(l + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc9bce0-2866-4041-9e0a-b1ad53b8b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 005b2j4b 2\n",
      "1 0 00fmeepz 1\n",
      "1 0 g7dhmyyo 2\n"
     ]
    }
   ],
   "source": [
    "!head -3 ../../ipynb/beir-evaluation-data/incomplete-beir-trec-covid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32b67de-fdd1-4036-8602-c8ae75006532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 005b2j4b 1 2\n",
      "1 0 00fmeepz 1 1\n",
      "1 0 g7dhmyyo 1 2\n"
     ]
    }
   ],
   "source": [
    "!head -3 incomplete-beir-trec-covid-for-sample-eval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef19e68-7d9b-49e9-a38e-7e61bf500bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infNDCG\t\tall\t\t0.6435\n"
     ]
    }
   ],
   "source": [
    "!./sample_eval_depth_10.pl incomplete-beir-trec-covid-for-sample-eval.txt ../../ipynb/beir-evaluation-data/runs/ance-09-01-2023-run.txt |grep infNDCG\n",
    "\n",
    "# This yields an infNDCG of 0.6435 which is even below assuming all unjudged to be non-relevant, which would get 0.652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38b32c0-d4ae-478f-8ed5-c9392fea0d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infNDCG\t\tall\t\t0.4746\n"
     ]
    }
   ],
   "source": [
    "!./sample_eval_depth_10.pl incomplete-beir-trec-covid-for-sample-eval.txt ../../ipynb/beir-evaluation-data/runs/tas-b-09-01-2023-run.txt | grep infNDCG\n",
    "\n",
    "# This yields an infNDCG of 0.4746 which is even below assuming all unjudged to be non-relevant, which would get 0.481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "819272dd-461f-431e-b3ad-b56779f9407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infNDCG\t\tall\t\t0.6703\n"
     ]
    }
   ],
   "source": [
    "!./sample_eval_depth_10.pl incomplete-beir-trec-covid-for-sample-eval.txt ../../ipynb/beir-evaluation-data/runs/colbert-ranking-26-12-2022-run.txt | grep infNDCG\n",
    "\n",
    "# This yields an infNDCG of 0.6703 which is even below assuming all unjudged to be non-relevant, which would get 0.680"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702d4d6-2e14-466b-8d3d-6ceac4c119d3",
   "metadata": {},
   "source": [
    "In all three cases, the infNDCG even underestimates the nDCG when assuming all unjudged documents are non-relevant, confirming my initial line of thought that infNDCG is better suited for the construction of the judgment set, but can conceptually not applied to our post-hoc evaluation on pooled relevance judgments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
